# Assignment 1 - An Introduction to Analytics {.unnumbered}

The following link will lead you to the assignment on the edX website:
[https://learning.edx.org/course/course-v1:MITx+15.071x+2T2020/block-v1:MITx+15.071x+2T2020+type@sequential+block@a5915d0492804dada5feb1926ba5be7a](https://learning.edx.org/course/course-v1:MITx+15.071x+2T2020/block-v1:MITx+15.071x+2T2020+type@sequential+block@a5915d0492804dada5feb1926ba5be7a)

## An Analytical Detective

There are two main types of crimes: violent crimes, and property crimes. In this problem, we'll focus on one specific type of property crime, called "motor vehicle theft" (sometimes referred to as grand theft auto). This is the act of stealing, or attempting to steal, a car. In this problem, we'll use some basic data analysis in R to understand the motor vehicle thefts in Chicago.

Please download the file [mvtWeek1.csv](https://courses.edx.org/assets/courseware/v1/96f9b8f751467da3a4b8a5be33e32905/asset-v1:MITx+15.071x+2T2020+type@asset+block/mvtWeek1.csv) for this problem (do not open this file in any spreadsheet software before completing this problem because it might change the format of the Date field).

***Start:***\
Read the dataset mvtWeek1.csv into R, using the read.csv function, and call the data frame "mvt".

```{r}
mvt <- read.csv("/cloud/project/analyticsedge/Datasets/DatasetsUnit1/mvtWeek1.csv")
```

**1.1: How many rows of data (observations) are in this dataset?**\
Answer: 191641

```{r}
nrow(mvt)
```

**1.2: How many variables are in this dataset?**\
Answer: 11

```{r}
ncol(mvt)
```

**1.3: Using the "max" function, what is the maximum value of the variable "ID"?**\
Answer: 9181151

```{r}
max(mvt$ID)
```

**1.4: What is the minimum value of the variable "Beat"?**\
Answer: 111

```{r}
min(mvt$Beat)
```

**1.5: How many observations have value TRUE in the Arrest variable (this is the number of crimes for which an arrest was made)?**\
Answer: 15536

```{r}
sum(mvt$Arrest)
```

**1.6: How many observations have a LocationDescription value of ALLEY?**\
Answer: 2308

```{r}
sum(mvt$LocationDescription == "ALLEY")
```

**2.1: In what format are the entries in the variable Date?**\
Answer: Month/Day/Year Hour:Minute

```{r}
mvt$Date[1]
```

**2.2: What is the month and year of the median date in our dataset? Enter your answer as "Month Year", without the quotes.**\
Answer: May 2006

```{r}
DateConvert = as.Date(strptime(mvt$Date, "%m/%d/%y %H:%M"))
#summary(DateConvert)
median(DateConvert)
```

**2.3: In which month did the fewest motor vehicle thefts occur?**\
Answer: February

```{r}
mvt$Month = months(DateConvert)
mvt$Weekday = weekdays(DateConvert)
mvt$Date = DateConvert
table(mvt$Month)
```

**2.4: On which weekday did the most motor vehicle thefts occur?**\
Answer: Friday

```{r}
table(mvt$Weekday)
```

**2.5: Which month has the largest number of motor vehicle thefts for which an arrest was made?**\
Answer: January

```{r}
table(mvt$Month, mvt$Arrest)
```

**3.1.1: In general, does it look like crime increases or decreases from 2002 - 2012?**\
Answer: Decreases

**3.1.2: In general, does it look like crime increases or decreases from 2005 - 2008?**\
Answer: Decreases

**3.1.3: In general, does it look like crime increases or decreases from 2009 - 2011?**\
Answer: Increases

```{r}
hist(mvt$Date, breaks=100)
```

**3.2: Does it look like there were more crimes for which arrests were made in the first half of the time period or the second half of the time period?**\
Answer: First half

```{r}
boxplot(Date ~ Arrest, data = mvt)
```

**3.3: For what proportion of motor vehicle thefts in 2001 was an arrest made?**\
Answer: 0.1041173

```{r}
tapply(mvt$Arrest, mvt$Year, mean)
```

**3.4: For what proportion of motor vehicle thefts in 2007 was an arrest made?**\
Answer: 0.08487395

```{r}
tapply(mvt$Arrest, mvt$Year, mean)
```

**3.5: For what proportion of motor vehicle thefts in 2012 was an arrest made?**\
Answer: 0.03902924

```{r}
tapply(mvt$Arrest, mvt$Year, mean)
```

**4.1: Which locations are the top five locations for motor vehicle thefts, excluding the "Other" category?**\
Answer: STREET, PARKING LOT/GARAGE(NON.RESID.), ALLEY, GAS STATION, DRIVEWAY - RESIDENTIAL

```{r}
sort(table(mvt$LocationDescription), decreasing = TRUE)
```

**Create a subset of your data, only taking observations for which the theft happened in one of these five locations, and call this new data set "Top5":**

```{r}
Top5 <- subset(mvt, mvt$LocationDescription == "STREET"
       | mvt$LocationDescription == "PARKING LOT/GARAGE(NON.RESID.)" 
       | mvt$LocationDescription == "ALLEY"
       | mvt$LocationDescription == "GAS STATION"
       | mvt$LocationDescription == "DRIVEWAY - RESIDENTIAL")
```

**4.2: How many observations are in Top5?**\
Answer: 177510

```{r}
nrow(Top5)
```

**4.3: One of the locations has a much higher arrest rate than the other locations. Which is it?**\
Answer: Gas Station (Check percentages)

```{r}
Top5$LocationDescription = factor(Top5$LocationDescription)
table(Top5$LocationDescription, Top5$Arrest)
```

**4.4: On which day of the week do the most motor vehicle thefts at gas stations happen?**\
Answer: Saturday

```{r}
table(Top5$LocationDescription == "GAS STATION", Top5$Weekday)
```

**4.5: On which day of the week do the fewest motor vehicle thefts in residential driveways happen?**\
Answer: Saturday

```{r}
table(Top5$LocationDescription == "DRIVEWAY - RESIDENTIAL", Top5$Weekday)
```

## Stock Dynamics

A stock market is where buyers and sellers trade shares of a company, and is one of the most popular ways for individuals and companies to invest money. The size of the world stock market is now estimated to be in the trillions. The largest stock market in the world is the New York Stock Exchange (NYSE), located in New York City. About 2,800 companies are listed on the NYSE. In this problem, we'll look at the monthly stock prices of five of these companies: IBM, General Electric (GE), Procter and Gamble, Coca Cola, and Boeing. The data used in this problem comes from Infochimps.

Please download the following files: [IBMStock.csv](https://courses.edx.org/assets/courseware/v1/4fc08d10f171aacf2ef61c6b4b5bb4d8/asset-v1:MITx+15.071x+2T2020+type@asset+block/IBMStock.csv), [GEStock.csv](https://courses.edx.org/assets/courseware/v1/448b8be4693d913c2b5153be0c0e25d6/asset-v1:MITx+15.071x+2T2020+type@asset+block/GEStock.csv), [ProcterGambleStock.csv](https://courses.edx.org/assets/courseware/v1/bb6ed54230b5b2e29fb66819ed535da0/asset-v1:MITx+15.071x+2T2020+type@asset+block/ProcterGambleStock.csv), [CocaColaStock.csv](https://courses.edx.org/assets/courseware/v1/4c30fd7f4f55e537989ca13a6db36289/asset-v1:MITx+15.071x+2T2020+type@asset+block/CocaColaStock.csv), [BoeingStock.csv](https://courses.edx.org/assets/courseware/v1/2e8c9fb294db48e5a999c747b317722d/asset-v1:MITx+15.071x+2T2020+type@asset+block/BoeingStock.csv) (do not open these files in any spreadsheet software before completing this problem because it might change the format of the Date field).

***Start:***\
Read the datasets into R, using the read.csv function, and call the data frames "IBM", "GE", "ProcterGamble", "CocaCola", and "Boeing", respectively.

```{r}
IBM <- read.csv("/cloud/project/analyticsedge/Datasets/DatasetsUnit1/IBMStock.csv")
GE <- read.csv("/cloud/project/analyticsedge/Datasets/DatasetsUnit1/GEStock.csv")
ProcterGamble <- read.csv("/cloud/project/analyticsedge/Datasets/DatasetsUnit1/ProcterGambleStock.csv")
CocaCola <- read.csv("/cloud/project/analyticsedge/Datasets/DatasetsUnit1/CocaColaStock.csv")
Boeing <- read.csv("/cloud/project/analyticsedge/Datasets/DatasetsUnit1/BoeingStock.csv")
```

Before working with these data sets, we need to convert the dates into a format that R can understand. Take a look at the structure of one of the datasets using the str function. Right now, the date variable is stored as a factor. We can convert this to a "Date" object in R by using the following five commands (one for each data set):

```{r}
IBM$Date = as.Date(IBM$Date, "%m/%d/%y")
GE$Date = as.Date(GE$Date, "%m/%d/%y")
CocaCola$Date = as.Date(CocaCola$Date, "%m/%d/%y")
ProcterGamble$Date = as.Date(ProcterGamble$Date, "%m/%d/%y")
Boeing$Date = as.Date(Boeing$Date, "%m/%d/%y")
```

**1.1: Our five datasets all have the same number of observations. How many observations are there in each data set?**\
Answer: 480

```{r}
nrow(IBM)
```

**1.2: What is the earliest year in our datasets?**\
Answer: 1970

```{r}
min(IBM$Date)
```

**1.3: What is the latest year in our datasets?**\
Answer: 2009

```{r}
max(IBM$Date)
```

**1.4: What is the mean stock price of IBM over this time period?**\
Answer: 144.375

```{r}
mean(IBM$StockPrice)
```

**1.5: What is the minimum stock price of General Electric (GE) over this time period?**\
Answer: 9.293636

```{r}
min(GE$StockPrice)
```

**1.6: What is the maximum stock price of Coca-Cola over this time period?**\
Answer: 146.5843

```{r}
max(CocaCola$StockPrice)
```

**1.7: What is the median stock price of Boeing over this time period?**\
Answer:

```{r}
median(Boeing$StockPrice)
```

**1.8: What is the standard deviation of the stock price of Procter & Gamble over this time period?**\
Answer: 18.19414

```{r}
sd(ProcterGamble$StockPrice)
```

Side note: According to the assignment, questions 1.2 - 1.7 should've been solved using the summary function. However, I used commands that would give more accurate answer. Along with the commands I used, I also wrote how the assignment could be solved using the summary function.

**2.1.1: Around what year did Coca-Cola has its highest stock price in this time period?**\
Answer: 1973

**2.1.2: Around what year did Coca-Cola has its lowest stock price in this time period?**\
Answer: 1980

```{r}
plot(CocaCola$Date, CocaCola$StockPrice, "l")
```

**2.2: In March of 2000, the technology bubble burst, and a stock market crash occurred. According to this plot, which company's stock dropped more?**\
Answer: Procter and Gamble

```{r}
plot(CocaCola$Date, CocaCola$StockPrice, "l", col = "red")
lines(ProcterGamble$Date, ProcterGamble$StockPrice, col = "blue")
abline(v=as.Date(c("2000-03-01")), lwd=2)
```

**2.3.1: Around 1983, the stock for one of these companies (Coca-Cola or Procter and Gamble) was going up, while the other was going down. Which one was going up?**\
Answer: CocaCola

**2.3.1: In the time period shown in the plot, which stock generally has lower values?**\
Answer: CocaCola

```{r}
plot(CocaCola$Date, CocaCola$StockPrice, "l", col = "red")
lines(ProcterGamble$Date, ProcterGamble$StockPrice, col = "blue")
abline(v=as.Date(c("1983-01-01")))
```

**Plot to answer the following questions:**

```{r}
plot(CocaCola$Date[301:432], CocaCola$StockPrice[301:432], type="l", col="red", ylim=c(0,210))
lines(ProcterGamble$Date[301:432], ProcterGamble$StockPrice[301:432], col = "blue")
lines(IBM$Date[301:432], IBM$StockPrice[301:432], col = "green")
lines(GE$Date[301:432], GE$StockPrice[301:432], col = "purple")
lines(Boeing$Date[301:432], Boeing$StockPrice[301:432], col = "orange")
```

**3.1: Which stock fell the most right after the technology bubble burst in March 2000?**\
Answer: General Electric (GE)

```{r}
plot(CocaCola$Date[301:432], CocaCola$StockPrice[301:432], type="l", col="red", ylim=c(0,210))
lines(ProcterGamble$Date[301:432], ProcterGamble$StockPrice[301:432], col = "blue")
lines(IBM$Date[301:432], IBM$StockPrice[301:432], col = "green")
lines(GE$Date[301:432], GE$StockPrice[301:432], col = "purple")
lines(Boeing$Date[301:432], Boeing$StockPrice[301:432], col = "orange")
abline(v = as.Date(c("2000-03-01")))
```

**3.2: Which stock reaches the highest value in the time period 1995-2005?**\
Answer: IBM

**3.3: Comparing September 1997 to November 1997, which companies saw a decreasing trend in their stock price?**\
Answer: Procer and Gamble, Boeing

```{r}
plot(CocaCola$Date[301:432], CocaCola$StockPrice[301:432], type="l", col="red", ylim=c(0,210))
lines(ProcterGamble$Date[301:432], ProcterGamble$StockPrice[301:432], col = "blue")
lines(IBM$Date[301:432], IBM$StockPrice[301:432], col = "green")
lines(GE$Date[301:432], GE$StockPrice[301:432], col = "purple")
lines(Boeing$Date[301:432], Boeing$StockPrice[301:432], col = "orange")
abline(v = as.Date(c("1997-09-1")))
abline(v = as.Date(c("1997-11-1")))
```

**3.4: In the last two years of this time period (2004 and 2005) which stock seems to be performing the best, in terms of increasing stock price?**\
Answer: Boeing

**4.1: In which months has IBM historically had a higher stock price (on average)?**\
Answer: January, February, March, April, May

```{r}
tapply(IBM$StockPrice, months(IBM$Date), mean) > mean(IBM$StockPrice)
```

**4.2: General Electric and Coca-Cola both have their highest average stock price in the same month. Which month is this?**\
Answer: April

```{r}
tapply(GE$StockPrice, months(GE$Date), mean) == max(tapply(GE$StockPrice, months(GE$Date), mean))
```

**4.3: For the months of December and January, every company's average stock is higher in one month and lower in the other. In which month are the stock prices lower?**\
Answer: December

```{r}
tapply(GE$StockPrice, months(GE$Date), mean)
```

## Demographics and Employment in the United States

In the wake of the Great Recession of 2009, there has been a good deal of focus on employment statistics, one of the most important metrics policymakers use to gauge the overall strength of the economy. In the United States, the government measures unemployment using the Current Population Survey (CPS), which collects demographic and employment information from a wide range of Americans each month. In this exercise, we will employ the topics reviewed in the lectures as well as a few new techniques using the September 2013 version of this rich, nationally representative dataset (available online).

The observations in the dataset represent people surveyed in the September 2013 CPS who actually completed a survey. While the full dataset has 385 variables, in this exercise we will use a more compact version of the dataset.

Please dowload the following file: [CPSData.csv](https://courses.edx.org/assets/courseware/v1/f041f6c100061fc06bc3b6320e6512fa/asset-v1:MITx+15.071x+2T2020+type@asset+block/CPSData.csv)

***Start:***\
Load the dataset from CPSData.csv into a data frame called CPS.

```{r}
CPS <- read.csv("/cloud/project/analyticsedge/Datasets/DatasetsUnit1/CPSData.csv")
```

**1.1: How many interviewees are in the dataset?**\
Answer: 131302

```{r}
nrow(CPS)
```

**1.2: Among the interviewees with a value reported for the Industry variable, what is the most common industry of employment?**\
Answer: Educational and health services

```{r}
head(sort(table(CPS$Industry), decreasing = TRUE), 1)
```

**1.3.1: Which state has the fewest interviewees?**\
Answer: New Mexico

```{r}
tail(sort(table(CPS$State), decreasing = TRUE), 1)
```

**1.3.2: Which state has the largest number of interviewees?**\
Answer: California

```{r}
head(sort(table(CPS$State), decreasing = TRUE), 1)
```

**1.4: What proportion of interviewees are citizens of the United States?**\
Answer: 0.9421943

```{r}
table(CPS$Citizenship)
(116639 + 7073)/nrow(CPS)
```

**1.5: For which races are there at least 250 interviewees in the CPS dataset of Hispanic ethnicity?**\
Answer: American Indian, Black, Multiracial, White

```{r}
table(CPS$Race, CPS$Hispanic) > 250
```

**2.1: Which variables have at least one interviewee with a missing (NA) value?**\
Answer: MetroAreaCode, Married, Education, EmploymentStatus, Industry

```{r}
names(which(colSums(is.na(CPS)) > 0))
```

**2.2: We will try to determine if there is a pattern in the missing values of the Married variable.**\
Answer: The Married variable being missing is related to the Age value for the interviewee.

```{r}
table(CPS$Region, is.na(CPS$Married))
table(CPS$Sex, is.na(CPS$Married))
table(CPS$Age, is.na(CPS$Married))
table(CPS$Citizenship, is.na(CPS$Married))
```

**2.3.1: How many states had all interviewees living in a non-metropolitan area (aka they have a missing MetroAreaCode value)? For this question, treat the District of Columbia as a state (even though it is not technically a state).**\
Answer: 2

**2.3.2: How many states had all interviewees living in a metropolitan area? Again, treat the District of Columbia as a state.**\
Answer: 3

```{r}
table(CPS$State, is.na(CPS$MetroAreaCode))
```

**2.4: Which region of the United States has the largest proportion of interviewees living in a non-metropolitan area?**\
Answer: Midwest

```{r}
table(CPS$Region, is.na(CPS$MetroAreaCode))
```

**2.5.1: Which state has a proportion of interviewees living in a non-metropolitan area closest to 30%?**\
Answer: Wisconsin

**2.5.2: Which state has the largest proportion of non-metropolitan interviewees, ignoring states where all interviewees were non-metropolitan?**\
Answer: Montana

```{r}
sort(tapply(is.na(CPS$MetroAreaCode), CPS$State, mean))
```

Codes like MetroAreaCode and CountryOfBirthCode are a compact way to encode factor variables with text as their possible values, and they are therefore quite common in survey datasets. In fact, all but one of the variables in this dataset were actually stored by a numeric code in the original CPS datafile.

When analyzing a variable stored by a numeric code, we will often want to convert it into the values the codes represent. To do this, we will use a dictionary, which maps the the code to the actual value of the variable. We have provided dictionaries [MetroAreaCodes.csv](https://courses.edx.org/assets/courseware/v1/fd88455abc1b5b69112daf70f3bb0c77/asset-v1:MITx+15.071x+2T2020+type@asset+block/MetroAreaCodes.csv) and [CountryCodes.csv](https://courses.edx.org/assets/courseware/v1/763710fa6703caea1cf9c708e31e99a3/asset-v1:MITx+15.071x+2T2020+type@asset+block/CountryCodes.csv), which respectively map MetroAreaCode and CountryOfBirthCode into their true values. 
**Read these two dictionaries into data frames MetroAreaMap and CountryMap:**

```{r}
MetroAreaMap <- read.csv("/cloud/project/analyticsedge/Datasets/DatasetsUnit1/MetroAreaCodes.csv")
CountryMap <- read.csv("/cloud/project/analyticsedge/Datasets/DatasetsUnit1/CountryCodes.csv")
```

**3.1.1: How many observations (codes for metropolitan areas) are there in MetroAreaMap?**\
Answer: 271

```{r}
nrow(MetroAreaMap)
```

**3.1.2: How many observations (codes for countries) are there in CountryMap?**\
Answer: 149

```{r}
nrow(CountryMap)
```

**To merge in the metropolitan areas, we want to connect the field MetroAreaCode from the CPS data frame with the field Code in MetroAreaMap. The following command merges the two data frames on these columns, overwriting the CPS data frame with the result:**

```{r}
CPS = merge(CPS, MetroAreaMap, by.x = "MetroAreaCode", by.y = "Code", all.x = TRUE)
```

**3.2.1: hat is the name of the variable that was added to the data frame by the merge() operation?**\
Answer: MetroArea

```{r}
str(CPS)
```

**3.2.2: How many interviewees have a missing value for the new metropolitan area variable?**\
Answer: 34238

```{r}
sum(is.na(CPS$MetroArea))
```

**3.3: Which of the following metropolitan areas has the largest number of interviewees?**\
Answer: Boston-Cambridge-Quincy, MA-NH

```{r}
sort(table(CPS$MetroArea), decreasing = TRUE)
```

**3.4: Which metropolitan area has the highest proportion of interviewees of Hispanic ethnicity?**\
Answer: Laredo, TX

```{r}
head(sort(tapply(CPS$Hispanic, CPS$MetroArea, mean), decreasing = TRUE), 1)
```

**3.5: Determine the number of metropolitan areas in the United States from which at least 20% of interviewees are Asian.**\
Answer: 4

```{r}
sum(sort(tapply(CPS$Race == "Asian", CPS$MetroArea, mean), decreasing = TRUE) > 0.2)
```

**3.6: Determine which metropolitan area has the smallest proportion of interviewees who have received no high school diploma.**\
Answer: Iowa City, IA

```{r}
head(sort(tapply(CPS$Education == "No high school diploma", CPS$MetroArea, mean, na.rm = TRUE)), 1)
```

**Just as we did with the metropolitan area information, merge in the country of birth information from the CountryMap data frame, replacing the CPS data frame with the result:**

```{r}
CPS = merge(CPS, CountryMap, by.x = "CountryOfBirthCode", by.y = "Code", all.x = TRUE)
```

**4.1.1: What is the name of the variable added to the CPS data frame by this merge operation?**\
Answer: Country

```{r}
str(CPS)
```

**4.1.2: How many interviewees have a missing value for the new country of birth variable?**\
Answer: 176

```{r}
sum(is.na(CPS$Country))
```

**4.2: Among all interviewees born outside of North America, which country was the most common place of birth?**\
Answer: Philippines

```{r}
head(sort(table(CPS$Country), decreasing = TRUE), 3)
```

**4.3: What proportion of the interviewees from the "New York-Northern New Jersey-Long Island, NY-NJ-PA" metropolitan area have a country of birth that is not the United States? For this computation, don't include people from this metropolitan area who have a missing country of birth.**\
Answer: 0.3086603

```{r}
tapply(CPS$Country != "United States", CPS$MetroArea == "New York-Northern New Jersey-Long Island, NY-NJ-PA", mean, na.rm = TRUE)
```

**4.4: Which metropolitan area has the largest number (note -- not proportion) of interviewees with a country of birth...** **4.4.1: ...in India?**\
Answer: New York-Northern New Jersey-Long Island, NY-NJ-PA

```{r}
tail(sort(tapply(CPS$Country == "India", CPS$MetroArea, sum, na.rm = TRUE)), 1)
```

**4.4.2: ...in Brazil?**\
Answer: Boston-Cambridge-Quincy, MA-NH

```{r}
tail(sort(tapply(CPS$Country == "Brazil", CPS$MetroArea, sum, na.rm = TRUE)), 1)
```

**4.4.3: ...in Somalia?**\
Answer: Minneapolis-St Paul-Bloomington, MN-WI

```{r}
tail(sort(tapply(CPS$Country == "Somalia", CPS$MetroArea, sum, na.rm = TRUE)), 1)
```

## Internet Privacy Poll (OPTIONAL)

Internet privacy has gained widespread attention in recent years. To measure the degree to which people are concerned about hot-button issues like Internet privacy, social scientists conduct polls in which they interview a large number of people about the topic. In this assignment, we will analyze data from a July 2013 Pew Internet and American Life Project poll on Internet anonymity and privacy, which involved interviews across the United States. While the full polling data can be found here, we will use a more limited version of the results, available in [AnonymityPoll.csv](https://courses.edx.org/assets/courseware/v1/f2c3bdcba475ddd1399e001dd98f4fd0/asset-v1:MITx+15.071x+2T2020+type@asset+block/AnonymityPoll.csv).

***Start:***\
Using read.csv(), load the dataset from AnonymityPoll.csv into a data frame called poll.

```{r}
poll <- read.csv("/cloud/project/analyticsedge/Datasets/DatasetsUnit1/AnonymityPoll.csv")
```

**1.1: How many people participated in the poll?**\
Answer: 1002

```{r}
nrow(poll)
```

**1.2.1: How many interviewees responded that they use a smartphone?**\
Answer: 487

```{r}
sum(poll$Smartphone, na.rm = TRUE)
```

**1.2.2: How many interviewees responded that they don't use a smartphone?**\
Answer: 472

```{r}
table(poll$Smartphone)
```

**1.2.3: How many interviewees did not respond to the question, resulting in a missing value, or NA, in the summary() output?**\
Answer: 43

```{r}
sum(is.na(poll$Smartphone))
```

**1.3.1: Which of the following are states in the Midwest census region?**\
Answer: Kansas, Missouri, Ohio

**1.3.2: Which was the state in the South census region with the largest number of interviewees?**\
Answer: Texas

```{r}
table(poll$Region, poll$State)
```

**2.1.1: How many interviewees reported not having used the Internet and not having used a smartphone?**\
Answer: 186

```{r}
tapply(poll$Internet.Use == 0, poll$Smartphone == 0, sum, na.rm = TRUE)
```

**2.1.2: How many interviewees reported having used the Internet and having used a smartphone?**\
Answer: 470

```{r}
tapply(poll$Internet.Use, poll$Smartphone, sum, na.rm = TRUE)
```

**2.1.3: How many interviewees reported having used the Internet but not having used a smartphone?**\
Answer: 285

```{r}
tapply(poll$Internet.Use == 1, poll$Smartphone == 0, sum, na.rm = TRUE)
```

**2.1.4: How many interviewees reported having used a smartphone but not having used the Internet?**\
Answer: 17

```{r}
tapply(poll$Internet.Use == 0, poll$Smartphone == 1, sum, na.rm = TRUE)
# Alternative to all 4 above questions: table(poll$Internet.Use, poll$Smartphone)
```

**2.2.1: How many interviewees have a missing value for their Internet use?**\
Answer: 1

```{r}
sum(is.na(poll$Internet.Use))
```

**2.2.2: How many interviewees have a missing value for their smartphone use?**\
Answer: 43

```{r}
sum(is.na(poll$Smartphone))
```

**Use the subset function to obtain a data frame called "limited", which is limited to interviewees who reported Internet use or who reported smartphone use:**

```{r}
limited <- subset(poll, poll$Internet.Use == 1
                        |poll$Smartphone == 1)
# Alternative: limited = subset(poll, Internet.Use == 1 | Smartphone == 1)
```

**2.3: How many interviewees are in the new data frame?**\
Answer: 792

```{r}
nrow(limited)
```

**3.1: Which variables have missing values in the limited data frame?**\
Answer: *Check output*

```{r}
names(which(colSums(is.na(limited)) > 0))
```

**3.2: What is the average number of pieces of personal information on the Internet, according to the Info.On.Internet variable?**\
Answer: 3.795455

```{r}
mean(limited$Info.On.Internet)
```

**3.3.1: How many interviewees reported a value of 0 for Info.On.Internet?**\
Answer: 105

```{r}
sum(limited$Info.On.Internet == 0)
```

**3.3.2: How many interviewees reported the maximum value of 11 for Info.On.Internet?**\
Answer: 8

```{r}
sum(limited$Info.On.Internet == 11)
```

**3.4: What proportion of interviewees who answered the Worry.About.Info question worry about how much information is available about them on the Internet?**\
Answer: 0.4886076

```{r}
table(limited$Worry.About.Info)
386/(404 + 386)
```

**3.5: What proportion of interviewees who answered the Anonymity.Possible question think it is possible to be completely anonymous on the Internet?**\
Answer: 0.3691899

```{r}
table(limited$Anonymity.Possible)
278/(475 + 278)
```

**3.6: What proportion of interviewees who answered the Tried.Masking.Identity question have tried masking their identity on the Internet?**\
Answer: 0.1632653

```{r}
table(limited$Tried.Masking.Identity)
128/(656 + 128)
```

**3.7: What proportion of interviewees who answered the Privacy.Laws.Effective question find United States privacy laws effective?**\
Answer: 0.2558459

```{r}
table(limited$Privacy.Laws.Effective)
186/(541 + 186)
```

**4.1: Build a histogram of the age of interviewees. What is the best represented age group in the population?**\
Answer: People aged about 60 years old.

```{r}
hist(limited$Age)
```

Both Age and Info.On.Internet are variables that take on many values, so a good way to observe their relationship is through a graph. We learned in lecture that we can plot Age against Info.On.Internet with the command `plot(limited$Age, limited$Info.On.Internet)`. However, because Info.On.Internet takes on a small number of values, multiple points will be plotted in exactly the same location on this graph, making the distribution hard to see:
```{r}
plot(limited$Age, limited$Info.On.Internet)
```


**4.2: What is the largest number of interviewees that have exactly the same value in their Age variable AND the same value in their Info.On.Internet variable?**\
Answer: 6

```{r}
max(table(limited$Age, limited$Info.On.Internet))
```

**4.3: Experimenting with the command jitter(c(1, 2, 3)), what appears to be the functionality of the jitter command?**\
Answer: jitter adds or subtracts a small amount of random noise to the values passed to it, and two runs will yield different results.

```{r}
jitter(c(1, 2, 3))
```

**4.4: What relationship to you observe between Age and Info.On.Internet?**\
Answer: Older age seems moderately associated with a smaller value for Info.On.Internet.

```{r}
plot(jitter(limited$Age), jitter(limited$Info.On.Internet))
```

**4.5.1: What is the average Info.On.Internet value for smartphone users?**\
Answer: 4.367556

**4.5.2: What is the average Info.On.Internet value for non-smartphone users?**\
Answer: 2.922807

```{r}
tapply(limited$Info.On.Internet, limited$Smartphone, mean, na.rm = TRUE)
```

**4.6.1: What proportion of smartphone users who answered the Tried.Masking.Identity question have tried masking their identity when using the Internet?**\
Answer: 0.1925466

**4.6.2: What proportion of non-smartphone users who answered the Tried.Masking.Identity question have tried masking their identity when using the Internet?**\
Answer: 0.1174377

```{r}
tapply(limited$Tried.Masking.Identity, limited$Smartphone, mean, na.rm = TRUE)
```
***And we're done! That was all for Assignment 1!***